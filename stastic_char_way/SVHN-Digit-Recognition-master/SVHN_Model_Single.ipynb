{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SVHN_Model_Single.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"NC_Ge_JuanPP","colab_type":"text"},"cell_type":"markdown","source":["# **Libraries We'll Be Using**"]},{"metadata":{"id":"zizXMhYgasQu","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import h5py\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn import preprocessing\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","from keras import regularizers\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n","from keras.layers.convolutional import Conv2D, MaxPooling2D\n","from keras.layers.core import Activation\n","\n","from keras.optimizers import RMSprop"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZxhSUM8HInM9","colab_type":"text"},"cell_type":"markdown","source":["# **Loading Preprocessed Dataset**"]},{"metadata":{"id":"oJWGcYNSkrM9","colab_type":"text"},"cell_type":"markdown","source":["**Loading the Data**"]},{"metadata":{"id":"KbCGA0-PL0LD","colab_type":"code","colab":{}},"cell_type":"code","source":["# open our uploaded file\n","svhn_data = h5py.File('SVHN_Preprocessed_Single.h5', 'r')\n","\n","# load the training, testing and validation set\n","X_train = svhn_data['X_train'][:]\n","y_train = svhn_data['y_train'][:]\n","X_test = svhn_data['X_test'][:]\n","y_test = svhn_data['y_test'][:]\n","X_val = svhn_data['X_val'][:]\n","y_val = svhn_data['y_val'][:]\n","\n","# close the file\n","svhn_data.close()\n","\n","\n","# check that our datasets are correct\n","print('Training X Shape: ', X_train.shape)\n","print('Training Y Shape: ', y_train.shape)\n","print('Testing X Shape: ', X_test.shape)\n","print('Testing Y Shape: ', y_test.shape)\n","print('Validation X Shape: ', X_val.shape)\n","print('Validation Y Shape: ', y_val.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"n1CvL5gYkhRq","colab_type":"text"},"cell_type":"markdown","source":["**Display Some Training Images**"]},{"metadata":{"id":"KLjWO_D4kmwH","colab_type":"code","colab":{}},"cell_type":"code","source":["def plot_images(images, nrows, ncols, cls_true, cls_pred=None):\n","    \n","    # plot n rows, m columns\n","    fig, axes = plt.subplots(nrows, ncols, figsize=(16, 2*nrows))\n","    \n","    # randomly select images\n","    rs = np.random.choice(images.shape[0], nrows*ncols)\n","    \n","    # For every axes object in the grid\n","    for i, ax in zip(rs, axes.flat): \n","        \n","        # get the image numbers\n","        true_number = ''.join(str(x) for x in cls_true[i] if x != 10)\n","        \n","        if cls_pred is None:\n","            title = \"True: {0}\".format(true_number)\n","        else:\n","            pred_number = ''.join(str(x) for x in cls_pred[i] if x != 10)\n","            title = \"True: {0}, Pred: {1}\".format(true_number, pred_number) \n","        \n","        \n","        # display images with true label\n","        ax.imshow(images[i,:,:,0], cmap='binary')\n","        ax.set_title(title)   \n","        ax.set_xticks([]); ax.set_yticks([])\n","        \n","        \n","# plot some images from the training set\n","plot_images(X_train, 2, 8, y_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pebDNVRZcYXL","colab_type":"text"},"cell_type":"markdown","source":["# **Create a CNN Model**\n"]},{"metadata":{"id":"f_ML5H-M_368","colab_type":"text"},"cell_type":"markdown","source":["**Single-Output Model**"]},{"metadata":{"id":"R79wtoTkc1yB","colab_type":"code","colab":{}},"cell_type":"code","source":["def cnn_model_single():\n","\n","  weight_decay = 1e-4\n","\n","  model = Sequential()\n","\n","  # LAYER 1\n","  model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), \n","                   input_shape=X_train.shape[1:]))\n","  model.add(Activation('elu'))\n","  model.add(BatchNormalization())\n","  model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","  model.add(Activation('elu'))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling2D(pool_size=(2,2)))\n","  model.add(Dropout(0.2))\n","\n","\n","  # LAYER 2\n","  model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","  model.add(Activation('elu'))\n","  model.add(BatchNormalization())\n","  model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","  model.add(Activation('elu'))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling2D(pool_size=(2,2)))\n","  model.add(Dropout(0.3))\n","\n","\n","  # LAYER 3\n","  model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","  model.add(Activation('elu'))\n","  model.add(BatchNormalization())\n","  model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n","  model.add(Activation('elu'))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling2D(pool_size=(2,2)))\n","  model.add(Dropout(0.4))\n","\n","\n","  # final layer has 11 activation layers\n","  # classes for 0-9 and a class for no digits\n","  model.add(Flatten())\n","  model.add(Dense(10, activation='softmax'))\n","\n","  return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rRHhNE9Ed6aw","colab_type":"text"},"cell_type":"markdown","source":["**Compile, train, and save our CNN model**"]},{"metadata":{"id":"ISwYGYNFeqE9","colab_type":"code","colab":{}},"cell_type":"code","source":["# create and compile our model\n","model = cnn_model_single()\n","model.compile(loss='categorical_crossentropy', \n","              optimizer = RMSprop(lr=0.001, decay=1e-6), \n","              metrics=[\"accuracy\"])\n","\n","\n","# parameters for model fitting\n","batch_size = 128\n","epochs = 5\n","\n","# train the model\n","model.fit(x=X_train, y=y_train,\n","          validation_data=(X_val, y_val),\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1)\n","\n","\n","# save our model\n","model.save(\"SVHN_model_single.h5\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qpUiK6iQ3Fe1","colab_type":"text"},"cell_type":"markdown","source":["**Check Model Accuracy**"]},{"metadata":{"id":"4ZTnCW2k3ReX","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.models import load_model\n","model = load_model(\"SVHN_model_single.h5\")\n","\n","# display final accuracy on validation set\n","scores = model.evaluate(X_val, y_val, verbose=0)\n","print(\"Validation Accuracy: %.2f%%\" % (scores[1]*100))\n","\n","\n","# use our cnn model to make predictions on the testing set\n","test_predictions = model.predict(X_test,)\n","\n","# accuracy score\n","test_accuracy = accuracy_score(y_test, test_predictions.round())\n","print(\"Test Accuracy Score: %.2f%%\" % (test_accuracy*100))\n","\n","# f1 score\n","test_f1 = f1_score(y_test, test_predictions.round(), average='micro')\n","print(\"Test F1 Score: %.2f%%\" % (test_f1*100))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sNSsaYSdrSa8","colab_type":"text"},"cell_type":"markdown","source":["**Dsiplay some predictions our model makes**"]},{"metadata":{"id":"LLENyjH8rXxj","colab_type":"code","colab":{}},"cell_type":"code","source":["import random\n","\n","# randomly select labels from the test dataset and see what the model predicted\n","for i in random.sample(range(0, len(X_test)), 5):\n","  print(\"Actual Label: \\t\\t\", np.argmax(y_test[i]))\n","  print(\"Predicted Label: \\t\", np.argmax(test_predictions[i]))\n","  print(\"\")"],"execution_count":0,"outputs":[]}]}